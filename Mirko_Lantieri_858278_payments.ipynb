{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Payments prediction with Neural Network\n",
    "\n",
    "In this notebook we shall provide the prediction of default payments made by clients in Taiwan from April to Semptember 2005. The execution of the Neural Network will be made step by step."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Importing libraries"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from pylab import rcParams\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rc\n",
    "from sklearn.model_selection import train_test_split\n",
    "import joblib\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format='retina'\n",
    "\n",
    "sns.set(style='whitegrid', palette='muted', font_scale=1.5)\n",
    "\n",
    "rcParams['figure.figsize'] = 16,10\n",
    "\n",
    "RANDOM_SEED = 60\n",
    "\n",
    "np.random.seed(RANDOM_SEED)\n",
    "tf.random.set_seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = pd.read_csv('data/X_test.csv')\n",
    "X_train = pd.read_csv('data/X_train.csv')\n",
    "y_train = pd.read_csv('data/y_train.csv')"
   ]
  },
  {
   "source": [
    "## Exploration"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Shape x test {X_test.shape}\")\n",
    "print(f\"Shape x train {X_train.shape}\")\n",
    "print(f\"Shape y train {y_train.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## First we verify if we have any missing data\n",
    "\n",
    "missing = X_train.isnull().sum()\n",
    "missing[missing > 0].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_y = y_train.isnull().sum()\n",
    "missing_y[missing_y > 0].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.index = X_train.ID\n",
    "X_test.index = X_test.ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Droppping the ID column\n",
    "X_train.drop('ID',axis=1,inplace=True)\n",
    "X_test.drop('ID',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train.rename(columns={\"default.payment.next.month\":\"def_payment\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.SEX.value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.EDUCATION.value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.rename(columns={\"PAY_0\":\"PAY_1\"})\n",
    "X_test = X_test.rename(columns={\"PAY_0\":\"PAY_1\"})\n",
    "\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "source": [
    "## Data visualization"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('fivethirtyeight')\n",
    "X_train.SEX.hist()\n",
    "plt.xlabel('SEX')\n",
    "plt.ylabel('COUNT')\n",
    "plt.title('SEX - COUNT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('fivethirtyeight')\n",
    "y_train.def_payment.hist()\n",
    "plt.xlabel('DEFAULT_PAY')\n",
    "plt.ylabel('COUNT')\n",
    "plt.title('Default Credit Card Clients - target value - data unbalance\\n (Default = 0, Not Default = 1)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('fivethirtyeight')\n",
    "X_train.EDUCATION.hist()\n",
    "plt.xlabel('EDUCATION')\n",
    "plt.ylabel('COUNT')\n",
    "plt.title('EDUCATION - COUNT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('fivethirtyeight')\n",
    "X_train.MARRIAGE.hist()\n",
    "plt.xlabel('MARRIAGE')\n",
    "plt.ylabel('COUNT')\n",
    "plt.title('MARRIAGE - COUNT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(x='SEX',y='LIMIT_BAL',data=X_train,hue='SEX')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x='SEX',data=X_train,hue='SEX')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x='def_payment', data=y_train, hue=\"def_payment\", palette=\"muted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simple method to plot the features\n",
    "def getFeatures(prefix):\n",
    "    return [prefix+str(x) for x in range(1,7)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pay_status_columns = getFeatures('PAY_')\n",
    "figure, ax = plt.subplots(2,3)\n",
    "figure.set_size_inches(18,8)\n",
    "\n",
    "\n",
    "for i in range(len(pay_status_columns)):\n",
    "    row,col = int(i/3), i%3\n",
    "\n",
    "    d  = X_train[pay_status_columns[i]].value_counts()\n",
    "    x = X_train[pay_status_columns[i]].value_counts()\n",
    "    ax[row,col].bar(d.index, d, align='center', color='red')\n",
    "    ax[row,col].bar(x.index, x, align='center', color='yellow', alpha=0.7)\n",
    "    ax[row,col].set_title(pay_status_columns[i])\n",
    "   \n",
    "\n",
    "\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x='MARRIAGE',y='AGE',data=X_train,palette='rainbow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x='EDUCATION',y='AGE',data=X_train,palette='rainbow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(X_train.LIMIT_BAL,kde=True,bins=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obeserving the correlation between features of dataset\n",
    "correlation = X_train.corr()\n",
    "plt.subplots(figsize=(30,10))\n",
    "sns.heatmap( correlation, square=True, annot=True, fmt=\".1f\" )"
   ]
  },
  {
   "source": [
    "## Preprocessing"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fil = (X_train.EDUCATION == 5) | (X_train.EDUCATION == 6) | (X_train.EDUCATION == 0)\n",
    "X_train.loc[fil, 'EDUCATION'] = 4\n",
    "X_train.EDUCATION.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fil = (X_test.EDUCATION == 5) | (X_test.EDUCATION == 6) | (X_test.EDUCATION == 0)\n",
    "X_test.loc[fil, 'EDUCATION'] = 4\n",
    "X_test.EDUCATION.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train['EDUCATION'].value_counts(dropna = False))\n",
    "print(X_test['EDUCATION'].value_counts(dropna = False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.loc[X_train.MARRIAGE == 0, 'MARRIAGE'] = 3\n",
    "X_train.MARRIAGE.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.loc[X_test.MARRIAGE == 0, 'MARRIAGE'] = 3\n",
    "X_test.MARRIAGE.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.plot(y = 'PAY_1',kind='hist')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.SEX.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[['PAY_AMT1', 'PAY_AMT2', 'PAY_AMT3', 'PAY_AMT4', 'PAY_AMT5', 'PAY_AMT6']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[['BILL_AMT1', 'BILL_AMT2', 'BILL_AMT3', 'BILL_AMT4', 'BILL_AMT5', 'BILL_AMT6']].describe()"
   ]
  },
  {
   "source": [
    "## Encoding of the categorical variable"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "categorical_vars = ['SEX','EDUCATION','MARRIAGE','PAY_1','PAY_2','PAY_3','PAY_4','PAY_5','PAY_6']\n",
    "X_train[categorical_vars].astype(str)\n",
    "X_test[categorical_vars].astype(str)\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.columns = X_train.columns.map(str.lower)\n",
    "X_test.columns = X_test.columns.map(str.lower)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "source": [
    "## Feature scaling"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizing the data\n",
    "col_to_norm = ['limit_bal', 'age', 'bill_amt1', 'bill_amt2', 'bill_amt3', 'bill_amt4',\n",
    "       'bill_amt5', 'bill_amt6', 'pay_amt1', 'pay_amt2', 'pay_amt3',\n",
    "       'pay_amt4', 'pay_amt5', 'pay_amt6']\n",
    "X_train[col_to_norm] = X_train[col_to_norm].apply(lambda x : (x-np.mean(x))/np.std(x))\n",
    "X_test[col_to_norm] = X_test[col_to_norm].apply(lambda x : (x-np.mean(x))/np.std(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
    "from sklearn.compose import make_column_transformer\n",
    "\n",
    "X = X_train\n",
    "y = np.array(y_train.def_payment.values)\n",
    "\n",
    "transformer = make_column_transformer(\n",
    "    (MinMaxScaler(), X_train.columns))\n",
    "transformer.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaling\n",
    "X = transformer.transform(X)"
   ]
  },
  {
   "source": [
    "## Splitting the training and test data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=RANDOM_SEED)\n",
    "X_train.shape"
   ]
  },
  {
   "source": [
    "# Neural Network Models"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## 1. Neural Network with 3 layers"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following method will help us plotting the F1-Score results\n",
    "def plot_f1(history):\n",
    "  hist = pd.DataFrame(history.history)\n",
    "  hist['epoch'] = history.epoch\n",
    "\n",
    "  plt.figure()\n",
    "  plt.xlabel('Epoch')\n",
    "  plt.ylabel('F1')\n",
    "  plt.plot(hist['epoch'], hist['loss'],\n",
    "            label='Train F1')\n",
    "  plt.plot(hist['epoch'], hist['val_loss'],\n",
    "            label = 'Val F1')\n",
    "  plt.legend()\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = keras.Sequential()\n",
    "model1.add(keras.layers.Dense(units=32, activation=\"relu\", input_shape=[X_train.shape[1]]))\n",
    "model1.add(keras.layers.Dense(units=64, activation=\"relu\"))\n",
    "model1.add(keras.layers.Dense(units=128, activation='relu'))\n",
    "\n",
    "model1.add(keras.layers.Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "model1.compile(\n",
    "    optimizer=keras.optimizers.Adam(0.0001),\n",
    "    loss = 'binary_crossentropy', \n",
    "    metrics = ['accuracy'])\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "early_stop = keras.callbacks.EarlyStopping(\n",
    "  monitor='val_loss',\n",
    "  mode=\"min\",\n",
    "  patience=10\n",
    ")\n",
    "\n",
    "history = model1.fit(\n",
    "  x=X_train,\n",
    "  y=y_train,\n",
    "  shuffle=True,\n",
    "  epochs=50,\n",
    "  validation_split=0.2,\n",
    "  batch_size=BATCH_SIZE\n",
    ")\n",
    "\n",
    "plot_f1(history)"
   ]
  },
  {
   "source": [
    "## 2. Neural Network with SGD Optimizer (4-layers)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model2 = keras.Sequential()\n",
    "model2.add(keras.layers.Dense(units=32, activation=\"relu\", input_shape=[X_train.shape[1]]))\n",
    "model2.add(keras.layers.Dense(units=64, activation=\"selu\"))\n",
    "model2.add(keras.layers.Dense(units=128, activation=\"selu\"))\n",
    "model2.add(keras.layers.Dense(units=256, activation=\"relu\"))\n",
    "model2.add(keras.layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model2.compile(\n",
    "    optimizer=keras.optimizers.SGD(0.0001),\n",
    "    loss='binary_crossentropy', \n",
    "    metrics = ['accuracy'])\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "early_stop = keras.callbacks.EarlyStopping(\n",
    "  monitor='val_loss',\n",
    "  mode=\"min\",\n",
    "  patience=10\n",
    ")\n",
    "\n",
    "history = model2.fit(\n",
    "  x=X_train,\n",
    "  y=y_train,\n",
    "  shuffle=True,\n",
    "  epochs=100,\n",
    "  validation_split=0.2,\n",
    "  batch_size=BATCH_SIZE\n",
    ")\n",
    "\n",
    "plot_f1(history)"
   ]
  },
  {
   "source": [
    "## 3. Neural Network with 4 layers and Adagrad Optimizer"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model3 = keras.Sequential()\n",
    "model3.add(keras.layers.Dense(units=64, activation=\"relu\", input_shape=[X_train.shape[1]]))\n",
    "model3.add(keras.layers.Dense(units=128, activation=\"linear\"))\n",
    "model3.add(keras.layers.Dense(units=256, activation=\"selu\"))\n",
    "model3.add(keras.layers.Dense(units=512, activation=\"relu\"))\n",
    "model3.add(keras.layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model3.compile(\n",
    "    optimizer=keras.optimizers.Adagrad(0.0001),\n",
    "    loss='binary_crossentropy', \n",
    "    metrics = ['accuracy'])\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "early_stop = keras.callbacks.EarlyStopping(\n",
    "  monitor='val_loss',\n",
    "  mode=\"min\",\n",
    "  patience=10\n",
    ")\n",
    "\n",
    "history = model3.fit(\n",
    "  x=X_train,\n",
    "  y=y_train,\n",
    "  shuffle=True,\n",
    "  epochs=100,\n",
    "  validation_split=0.2,\n",
    "  batch_size=BATCH_SIZE\n",
    ")\n",
    "\n",
    "plot_f1(history)"
   ]
  },
  {
   "source": [
    "## 4. Neural Network with dropout regularization at 30%"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model4 = keras.Sequential()\n",
    "model4.add(keras.layers.Dropout(0.3, input_shape=(X_train.shape[1],)))\n",
    "model4.add(keras.layers.Dense(units=128, activation=\"relu\"))\n",
    "model4.add(keras.layers.Dropout(0.3))\n",
    "model4.add(keras.layers.Dense(units=256, activation=\"relu\"))\n",
    "model4.add(keras.layers.Dropout(0.3))\n",
    "model4.add(keras.layers.Dense(units=512, activation=\"relu\"))\n",
    "model4.add(keras.layers.Dropout(0.3))\n",
    "model4.add(keras.layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model4.compile(\n",
    "    optimizer=keras.optimizers.SGD(0.0001),\n",
    "    loss = 'binary_crossentropy', \n",
    "    metrics = ['accuracy'])\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "early_stop = keras.callbacks.EarlyStopping(\n",
    "  monitor='val_loss',\n",
    "  mode=\"min\",\n",
    "  patience=15\n",
    ")\n",
    "\n",
    "history = model4.fit(\n",
    "  x=X_train,\n",
    "  y=y_train,\n",
    "  shuffle=True,\n",
    "  epochs=100,\n",
    "  validation_split=0.2,\n",
    "  batch_size=BATCH_SIZE\n",
    ")\n",
    "\n",
    "plot_f1(history)"
   ]
  },
  {
   "source": [
    "## Model Evaluation"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score, roc_auc_score\n",
    "\n",
    "# We add the predicted score to a file text\n",
    "f = open(\"Mirko_Lantieri_858278_score2.txt\", \"a\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model1.predict(X_test)\n",
    "f.write(f\"{np.around(y_pred)}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model2.predict(X_test)\n",
    "f.write(f\"{np.around(y_pred)}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model3.predict(X_test)\n",
    "f.write(f\"{np.around(y_pred)}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model4.predict(X_test)\n",
    "f.write(f\"{np.around(y_pred)}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.close()\n"
   ]
  },
  {
   "source": [
    "## Metrics evaluation Model 1"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc = roc_auc_score(y_test, model1.predict(X_test))\n",
    "f1 = f1_score(y_test, np.asarray(model1.predict(X_test)))\n",
    "acc = accuracy_score(y_test, np.asarray(model1.predict(X_test)))\n",
    "prec = precision_score(y_test, np.asarray(model1.predict(X_test)))\n",
    "recall = recall_score(y_test, np.asarray(model1.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame([['Logistic Regression', acc,prec,recall, f1,roc]],\n",
    "               columns = ['Model', 'Accuracy', 'Precision', 'Recall', 'F1 Score','ROC'])\n",
    "results"
   ]
  },
  {
   "source": [
    "## Metrics evaluation Model 2"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc = roc_auc_score(y_test, model2.predict(X_test))\n",
    "f1 = f1_score(y_test, np.asarray(model2.predict(X_test)))\n",
    "acc = accuracy_score(y_test, np.asarray(model2.predict(X_test)))\n",
    "prec = precision_score(y_test, np.asarray(model2.predict(X_test)))\n",
    "recall = recall_score(y_test, np.asarray(model2.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame([['Logistic Regression', acc,prec,recall, f1,roc]],\n",
    "               columns = ['Model', 'Accuracy', 'Precision', 'Recall', 'F1 Score','ROC'])\n",
    "results"
   ]
  },
  {
   "source": [
    "## Metrics evaluation Model 3"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc = roc_auc_score(y_test, model3.predict(X_test))\n",
    "f1 = f1_score(y_test, np.asarray(model3.predict(X_test)))\n",
    "acc = accuracy_score(y_test, np.asarray(model3.predict(X_test)))\n",
    "prec = precision_score(y_test, np.asarray(model3.predict(X_test)))\n",
    "recall = recall_score(y_test, np.asarray(model3.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame([['Logistic Regression', acc,prec,recall, f1,roc]],\n",
    "               columns = ['Model', 'Accuracy', 'Precision', 'Recall', 'F1 Score','ROC'])\n",
    "results"
   ]
  },
  {
   "source": [
    "## Metrics evaluation Model 4"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc = roc_auc_score(y_test, model4.predict(X_test))\n",
    "f1 = f1_score(y_test, np.asarray(model4.predict(X_test)))\n",
    "acc = accuracy_score(y_test, np.asarray(model4.predict(X_test)))\n",
    "prec = precision_score(y_test, np.asarray(model4.predict(X_test)))\n",
    "recall = recall_score(y_test, np.asarray(model4.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame([['Logistic Regression', acc,prec,recall, f1,roc]],\n",
    "               columns = ['Model', 'Accuracy', 'Precision', 'Recall', 'F1 Score','ROC'])\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "# false positive rate,fpr= FP/(TN+FP) OR fpr=1-specificty, tpr=sensitivity \n",
    "y_pred_1 = model1.predict(X_test)\n",
    "y_pred_2 = model2.predict(X_test)\n",
    "\n",
    "y_pred_3 = model3.predict(X_test)\n",
    "y_pred_4 = model4.predict(X_test)\n",
    "\n",
    "model = [model1,model2,model3,model4]\n",
    "\n",
    "models=[y_pred_1,y_pred_2,y_pred_3,y_pred_4]\n",
    "label=['Logistic','SGD','Adagrad','Dropout']\n",
    "\n",
    "# plotting ROC curves\n",
    "plt.figure(figsize=(10, 8))\n",
    "m=np.arange(4)\n",
    "for m in m:\n",
    "    fpr, tpr,thresholds= metrics.roc_curve(y_test,models[m])\n",
    "    auc = metrics.roc_auc_score(y_test,model[m].predict(X_test))\n",
    "    plt.plot(fpr, tpr, label='%s ROC (area = %0.2f)' % (label[m], auc))\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('1-Specificity(False Positive Rate)')\n",
    "plt.ylabel('Sensitivity(True Positive Rate)')\n",
    "plt.title('AUROC')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}